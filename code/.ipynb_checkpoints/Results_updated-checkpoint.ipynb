{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Author of code: William Godel \n",
    "\n",
    "Date: 07/02\n",
    "\n",
    "Purpose: to assess performance of ML models on test data (note, none of the gradient boosted tree stuff was used)\n",
    "\n",
    "## Data IN: \n",
    "\n",
    "### Data\n",
    "\n",
    "train_data_large.csv\n",
    "\n",
    "val_data_large.csv\n",
    "\n",
    "train_data_large_covid.csv\n",
    "\n",
    "val_data_large_covid.csv\n",
    "\n",
    "train_data_large_noncovid.csv\n",
    "\n",
    "val_data_large_noncovid.csv\n",
    "\n",
    "test_data_large.csv\n",
    "\n",
    "test_data_large_covid.csv\n",
    "\n",
    "test_data_large_noncovid.csv\n",
    "\n",
    "\n",
    "### models\n",
    "\n",
    "grid_rf.p\n",
    "\n",
    "grid_en.p\n",
    "\n",
    "model.pt\n",
    "\n",
    "model_nn_highpol.pt\n",
    "\n",
    "grid_rf_large.p\n",
    "\n",
    "grid_en_large.p\n",
    "\n",
    "model_large.pt\n",
    "\n",
    "\n",
    "## Data OUT:\n",
    "\n",
    "no data out\n",
    "\n",
    "Machine: My laptop or Imac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/williamgodel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "laptop = True\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from functions import count_mode, bayes_probs, bayes_binary\n",
    "from ml_functions import feature_creation, data_prep\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#crowd_size, feature_transform\n",
    "from path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/williamgodel/Dropbox/DS4E Spring 2020 Public/crowdsourcing_factchecking_public/code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(prepared_data + \"test_data_large.csv\")\n",
    "test_data_covid = pd.read_csv(prepared_data + \"test_data_large_covid.csv\")\n",
    "test_data_noncovid = pd.read_csv(prepared_data + \"test_data_large_noncovid.csv\")\n",
    "\n",
    "test_data_large = test_data.append(test_data_covid)\n",
    "test_data_large = test_data_large.append(test_data_noncovid)\n",
    "\n",
    "test_data_large.reset_index(inplace = True, drop = True)\n",
    "test_target_large = test_data_large['mode'] == 'FM'\n",
    "\n",
    "\n",
    "X_test = feature_creation(test_data_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(prepared_data + \"train_data_large.csv\")\n",
    "val_data = pd.read_csv(prepared_data + \"val_data_large.csv\")\n",
    "\n",
    "train_data_covid = pd.read_csv(prepared_data + \"train_data_large_covid.csv\")\n",
    "val_data_covid = pd.read_csv(prepared_data + \"val_data_large_covid.csv\")\n",
    "\n",
    "\n",
    "train_data_noncovid = pd.read_csv(prepared_data + \"train_data_large_noncovid.csv\")\n",
    "val_data_noncovid = pd.read_csv(prepared_data + \"val_data_large_noncovid.csv\")\n",
    "\n",
    "\n",
    "\n",
    "train_data_large = train_data.append(train_data_covid)\n",
    "train_data_large = train_data_large.append(train_data_noncovid)\n",
    "\n",
    "train_data_large.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "val_data_large = val_data.append(val_data_covid)\n",
    "val_data_large = val_data.append(val_data_noncovid)\n",
    "\n",
    "val_data_large.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "train_target_large = train_data_large['mode'] == 'FM'\n",
    "val_target_large = val_data_large['mode'] == 'FM'\n",
    "\n",
    "X_train = feature_creation(train_data_large)\n",
    "X_val = feature_creation(val_data_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = []\n",
    "\n",
    "resp_var = [x for x in X_train.columns if 'resp_veracity_' in x]\n",
    "new_cols = [x for x in X_train.columns if 'new' in x]\n",
    "\n",
    "#numeric_features.extend(resp_var)\n",
    "numeric_features.extend(resp_var) #rempve this if it doesn't work\n",
    "numeric_features.extend(new_cols)\n",
    "numeric_features.extend([\"crowd_means\",'crowd_median','crowd_full_range', 'crowd_IQR_range', \\\n",
    "                         'crowd_variance', 'crowd_bayes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_eval(preds, truth):\n",
    "    \n",
    "    if True in np.unique(truth):\n",
    "        \n",
    "        condition_pos = True\n",
    "        condition_neg = False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        condition_pos = 1\n",
    "        condition_neg = 0\n",
    "        \n",
    "    con_pos_count = np.sum(truth == condition_pos)\n",
    "    con_neg_count = np.sum(truth == condition_neg)\n",
    "        \n",
    "    accuracy = np.sum((preds == truth))/truth.size\n",
    "    \n",
    "    True_pos = np.sum(preds[truth == condition_pos] == truth[truth ==condition_pos])\n",
    "    False_pos = np.sum(preds[truth == condition_neg] != truth[truth == condition_neg])\n",
    "    \n",
    "    True_neg = np.sum(preds[truth == condition_neg] == truth[truth == condition_neg])\n",
    "    False_neg = np.sum(preds[truth == condition_pos] != truth[truth == condition_pos])\n",
    "    \n",
    "    \n",
    "    return accuracy, True_pos, False_pos, True_neg, False_neg\n",
    "    \n",
    "    \n",
    "def conf_perc(a_list):\n",
    "    \n",
    "    total_pos = sum(a_list[2:4])\n",
    "    total_neg = sum(a_list[4:])\n",
    "    print(\"TP\", \"FP\", \"TN\", \"FN\")\n",
    "    return a_list[2]/total_pos, a_list[3]/total_pos, a_list[4]/total_neg, a_list[5]/total_neg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387857142857143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - test_target_large.sum()/test_target_large.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_large.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "### standard crowd\n",
    "### size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = pickle.load(open(models + 'grid_rf.p', \"rb\" ))\n",
    "\n",
    "rf_list = [\"randomforest_10\"]\n",
    "\n",
    "all_results = list(conf_eval(grid_rf.predict(X_test), test_target_large))\n",
    "\n",
    "rf_list.extend(all_results)\n",
    "\n",
    "performance_dic['randomforest_10'] = rf_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['randomforest_10', 0.5770714285714286, 2405, 1869, 5674, 4052]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['randomforest_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5627047262517548,\n",
       " 0.43729527374824523,\n",
       " 0.5833847419288505,\n",
       " 0.4166152580711495)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['randomforest_10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "### standard crowd\n",
    "### size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elnet = pickle.load(open(models + 'grid_en.p', \"rb\" ))\n",
    "\n",
    "elnet_list = [\"elnet_10\"]\n",
    "\n",
    "el_preds = elnet.predict(X_test)\n",
    "\n",
    "all_results = list(conf_eval(el_preds, test_target_large))\n",
    "\n",
    "elnet_list.extend(all_results)\n",
    "\n",
    "performance_dic['elnet_10'] = elnet_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elnet_10', 0.5647857142857143, 1743, 1379, 6164, 4714]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['elnet_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5582959641255605,\n",
       " 0.44170403587443946,\n",
       " 0.5666482809339952,\n",
       " 0.4333517190660048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['elnet_10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "### standard crowd\n",
    "### size 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn = pickle.load(open(local_pickles + 'model.p', \"rb\" ))\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, 500) \n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "        self.fc3 = nn.Linear(100, 25)\n",
    "        self.fc4 = nn.Linear(25, 25)\n",
    "        self.fc5 = nn.Linear(25, 10)\n",
    "        self.fc6 = nn.Linear(10, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Net_dropout(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim):\n",
    "        super(Net_dropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, 500) \n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "        self.fc3 = nn.Linear(100, 25)\n",
    "        self.fc4 = nn.Linear(25, 25)\n",
    "        self.fc5 = nn.Linear(25, 10)\n",
    "        self.fc6 = nn.Linear(10, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)     \n",
    "        x = F.relu(self.fc3(x))    \n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "emb_dim = 61  \n",
    "net = Net_dropout(emb_dim)\n",
    "net.load_state_dict(torch.load(models + \"model.pt\"))\n",
    "net.eval()\n",
    "\n",
    "nn_list = [\"nn_10\"]\n",
    "\n",
    "# Preparing the data\n",
    "y_data_bin = np.where(test_target_large == True, 1, 0)\n",
    "\n",
    "test = StandardScaler()\n",
    "test.fit(X_train[numeric_features])\n",
    "\n",
    "#training data\n",
    "X_train_stand = X_test.copy()\n",
    "X_train_stand[numeric_features] = test.transform(X_test[numeric_features])\n",
    "\n",
    "\n",
    "train_dat_nn = data_prep(X_train_stand,test_target_large)\n",
    "\n",
    "nn_preds  = torch.sigmoid(net(torch.tensor(train_dat_nn[:][0]).float()))\n",
    "nn_preds = np.where(nn_preds > .5, 1,0).reshape(-1,)\n",
    "\n",
    "all_results = list(conf_eval(nn_preds, test_target_large))\n",
    "\n",
    "nn_list.extend(all_results)\n",
    "\n",
    "performance_dic['nn_10'] = nn_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_10', 0.6595, 2838, 1148, 6395, 3619]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['nn_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7119919719016558,\n",
       " 0.2880080280983442,\n",
       " 0.6386059516676653,\n",
       " 0.36139404833233474)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['nn_10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_large = feature_creation(test_data_large, crowd_num = 25)\n",
    "X_train_large = feature_creation(train_data_large, crowd_num = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "### Large crowd\n",
    "### size 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf_large = pickle.load(open(models + 'grid_rf_large.p', \"rb\" ))\n",
    "\n",
    "rf_list_large = [\"randomforest_25\"]\n",
    "\n",
    "all_results = list(conf_eval(grid_rf_large.predict(X_test_large), test_target_large))\n",
    "\n",
    "rf_list_large.extend(all_results)\n",
    "\n",
    "performance_dic['randomforest_25'] = rf_list_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['randomforest_25', 0.5965, 3046, 2238, 5305, 3411]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['randomforest_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5764572293716881,\n",
       " 0.42354277062831186,\n",
       " 0.6086507572280863,\n",
       " 0.39134924277191374)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['randomforest_25'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "### large crowd\n",
    "### size 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_en_large = pickle.load(open(models + 'grid_en_large.p', \"rb\" ))\n",
    "\n",
    "en_list_large = [\"elnet_25\"]\n",
    "\n",
    "el_preds_large = grid_en_large.predict(X_test_large)\n",
    "\n",
    "all_results = list(conf_eval(el_preds_large, test_target_large))\n",
    "\n",
    "en_list_large.extend(all_results)\n",
    "\n",
    "performance_dic['elnet_25'] = en_list_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elnet_25', 0.5627857142857143, 2063, 1727, 5816, 4394]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['elnet_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5443271767810026,\n",
       " 0.4556728232189974,\n",
       " 0.569637610186092,\n",
       " 0.43036238981390795)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['elnet_25'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "### Large crowd\n",
    "### size 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_large = []\n",
    "\n",
    "resp_var = [x for x in X_test_large.columns if 'resp_veracity_' in x]\n",
    "new_cols = [x for x in X_test_large.columns if 'new' in x]\n",
    "\n",
    "#numeric_features.extend(resp_var)\n",
    "numeric_features_large.extend(resp_var) #rempve this if it doesn't work\n",
    "numeric_features_large.extend(new_cols)\n",
    "numeric_features_large.extend([\"crowd_means\",'crowd_median','crowd_full_range', 'crowd_IQR_range', \\\n",
    "                         'crowd_variance', 'crowd_bayes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emb_dim = 121   \n",
    "net_large = Net(emb_dim)\n",
    "net_large.load_state_dict(torch.load(models + \"model_large.pt\"))\n",
    "net_large.eval()\n",
    "\n",
    "nn_list_large = [\"nn_25\"]\n",
    "\n",
    "# Preparing the data\n",
    "y_data_bin_large = np.where(test_target_large == True, 1, 0)\n",
    "\n",
    "\n",
    "test = StandardScaler()\n",
    "test.fit(X_train_large[numeric_features_large])\n",
    "\n",
    "#training data\n",
    "X_train_stand_large = X_test_large.copy()\n",
    "X_train_stand_large[numeric_features_large] = test.transform(X_test_large[numeric_features_large])\n",
    "\n",
    "train_dat_nn_large = data_prep(X_train_stand_large,test_target_large)\n",
    "\n",
    "nn_preds  = torch.sigmoid(net_large(torch.tensor(train_dat_nn_large[:][0]).float()))\n",
    "nn_preds = np.where(nn_preds > .5, 1,0).reshape(-1,)\n",
    "\n",
    "all_results = list(conf_eval(nn_preds, test_target_large))\n",
    "\n",
    "nn_list_large.extend(all_results)\n",
    "\n",
    "performance_dic['nn_25'] = nn_list_large\n",
    "\n",
    "#for use in feature importance\n",
    "pickle.dump(X_train_stand_large, open(data_pickles + \"X_test_stand_large.p\", \"wb\"))\n",
    "pickle.dump(test_target_large, open(data_pickles + \"test_target_large.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_stand = pickle.load(open(local_pickles + 'X_test_stand.p', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_25', 0.6813571428571429, 3163, 1167, 6376, 3294]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['nn_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7304849884526559, 0.2695150115473441, 0.659358841778697, 0.340641158221303)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['nn_25'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Pol Knowledge\n",
    "## test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_knowledge_df_test = pickle.load(open(data_pickles + 'pol_knowledge_df_test.p', \"rb\" ))\n",
    "X_data_pol_test = feature_creation(pol_knowledge_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest,\n",
    "### High PK, size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf_pol = pickle.load(open(models + 'grid_rf_pol.p', \"rb\" ))\n",
    "\n",
    "rf_list_highpk = [\"randomforest_highpk_10\"]\n",
    "\n",
    "all_results = list(conf_eval(grid_rf_pol.predict(X_data_pol_test), test_target_large))\n",
    "\n",
    "rf_list_highpk.extend(all_results)\n",
    "\n",
    "performance_dic['randomforest_highpk_10'] = rf_list_highpk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['randomforest_highpk_10', 0.6344285714285715, 3062, 1723, 5820, 3395]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['randomforest_highpk_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6399164054336468, 0.3600835945663532, 0.631578947368421, 0.3684210526315789)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['randomforest_highpk_10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN high pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_knowledge_df_train_orig = pickle.load(open(data_pickles + 'pol_knowledge_df_train_orig.p', \"rb\" ))\n",
    "# Preparing the data\n",
    "X_data_pol_train = feature_creation(pol_knowledge_df_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emb_dim = 61 \n",
    "net_large = Net(emb_dim)\n",
    "net_large.load_state_dict(torch.load(models + \"model_nn_highpol.pt\"))\n",
    "net_large.eval()\n",
    "\n",
    "nn_list_large = [\"nn_10_highpol\"]\n",
    "\n",
    "# Preparing the data\n",
    "y_data_bin_large = np.where(test_target_large == True, 1, 0)\n",
    "\n",
    "\n",
    "test = StandardScaler()\n",
    "test.fit(X_data_pol_train[numeric_features])\n",
    "\n",
    "#training data\n",
    "X_test_stand_large = X_data_pol_test.copy()\n",
    "X_test_stand_large[numeric_features] = test.transform(X_data_pol_test[numeric_features])\n",
    "\n",
    "\n",
    "test_dat_nn_large = data_prep(X_test_stand_large,y_data_bin_large)\n",
    "\n",
    "\n",
    "nn_preds  = torch.sigmoid(net_large(torch.tensor(test_dat_nn_large[:][0]).float()))\n",
    "nn_preds = np.where(nn_preds > .5, 1,0).reshape(-1,)\n",
    "\n",
    "\n",
    "all_results = list(conf_eval(nn_preds, test_target_large))\n",
    "\n",
    "nn_list_large.extend(all_results)\n",
    "\n",
    "performance_dic['nn_10_highpol'] = nn_list_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_10_highpol', 0.6815714285714286, 3586, 1587, 5956, 2871]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['nn_10_highpol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1427857142857143"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dic['nn_10_highpol'][1] - np.mean(~test_target_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6932147689928475,\n",
       " 0.30678523100715255,\n",
       " 0.6747479324798913,\n",
       " 0.32525206752010877)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_perc(performance_dic['nn_10_highpol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Name', \"Accuracy low cred\", \"True Pos low cred\", \"False Pos low cred\", \"True Neg low cred\", \"False Neg low cred\"]\n",
    "\n",
    "results_df_test = pd.DataFrame.from_dict(performance_dic, orient='index', columns = cols)\n",
    "results_df_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results_df_test, open(data_pickles + \"results_df_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy low cred</th>\n",
       "      <th>True Pos low cred</th>\n",
       "      <th>False Pos low cred</th>\n",
       "      <th>True Neg low cred</th>\n",
       "      <th>False Neg low cred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>randomforest_10</td>\n",
       "      <td>0.577071</td>\n",
       "      <td>2405</td>\n",
       "      <td>4052</td>\n",
       "      <td>5674</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elnet_10</td>\n",
       "      <td>0.564786</td>\n",
       "      <td>1743</td>\n",
       "      <td>4714</td>\n",
       "      <td>6164</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nn_10</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>2838</td>\n",
       "      <td>3619</td>\n",
       "      <td>6395</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>randomforest_25</td>\n",
       "      <td>0.596500</td>\n",
       "      <td>3046</td>\n",
       "      <td>3411</td>\n",
       "      <td>5305</td>\n",
       "      <td>2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elnet_25</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>2063</td>\n",
       "      <td>4394</td>\n",
       "      <td>5816</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nn_25</td>\n",
       "      <td>0.681357</td>\n",
       "      <td>3163</td>\n",
       "      <td>3294</td>\n",
       "      <td>6376</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>randomforest_highpk_10</td>\n",
       "      <td>0.634429</td>\n",
       "      <td>3062</td>\n",
       "      <td>3395</td>\n",
       "      <td>5820</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nn_10_highpol</td>\n",
       "      <td>0.681571</td>\n",
       "      <td>3586</td>\n",
       "      <td>2871</td>\n",
       "      <td>5956</td>\n",
       "      <td>1587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name  Accuracy low cred  True Pos low cred  \\\n",
       "0         randomforest_10           0.577071               2405   \n",
       "1                elnet_10           0.564786               1743   \n",
       "2                   nn_10           0.659500               2838   \n",
       "3         randomforest_25           0.596500               3046   \n",
       "4                elnet_25           0.562786               2063   \n",
       "5                   nn_25           0.681357               3163   \n",
       "6  randomforest_highpk_10           0.634429               3062   \n",
       "7           nn_10_highpol           0.681571               3586   \n",
       "\n",
       "   False Pos low cred  True Neg low cred  False Neg low cred  \n",
       "0                4052               5674                1869  \n",
       "1                4714               6164                1379  \n",
       "2                3619               6395                1148  \n",
       "3                3411               5305                2238  \n",
       "4                4394               5816                1727  \n",
       "5                3294               6376                1167  \n",
       "6                3395               5820                1723  \n",
       "7                2871               5956                1587  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_test.to_csv(\"ML_test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
