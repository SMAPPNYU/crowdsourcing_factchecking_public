{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author of code: William Godel \n",
    "\n",
    "Date: 07/02\n",
    "\n",
    "Purpose: to calculate the heuristic performance of high political knowledge crowds on both training and test sets\n",
    "\n",
    "## Data IN: \n",
    "\n",
    "pol_knowledge_df_test.p\n",
    "\n",
    "pol_knowledge_df.p\n",
    "\n",
    "## Data OUT: \n",
    "\n",
    "crowd_size_binary_high_pol.p\n",
    "\n",
    "crowd_size_binary_high_pol_test.p\n",
    "\n",
    "Machine: My laptop or Imac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook evaluates various transparent heuristic models - on high political knowledge crowds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "laptop = True\n",
    "import pickle\n",
    "\n",
    "from functions import bayes_binary, bayes_probs,crowd_mode,eval_comp,quick_graph, full_evaluation, crowd_mode, see_data, array_return\n",
    "\n",
    "\n",
    "from path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_fakesource = pickle.load( open( data_pickles + 'pol_knowledge_df_test.p', \"rb\" ) )\n",
    "train_data_fakesource = pickle.load( open( data_pickles + 'pol_knowledge_df.p', \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fakesource = train_data_fakesource.append(test_data_fakesource)\n",
    "all_data_fakesource.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowd size simulation\n",
    "\n",
    "## Only Questionable sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories\n",
    "\n",
    "For false according to FC:\n",
    "\n",
    "1. fcmodefalse = pure mode false or not\n",
    "2. rmfalse = robust mode false or not\n",
    "3. allfalse = all false or not\n",
    "4. anyfalse = any false set or not\n",
    "5. notrue = no true said against it or not\n",
    "\n",
    "## and then reverse for true\n",
    "\n",
    "Crowd Mode types:\n",
    "\n",
    "1. origmode = pure crowd mode\n",
    "2. nocnd = cnd discarded\n",
    "3. modefm = all cnd counted as fm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### constructing the combos of interest\n",
    "\n",
    "fc_types = ['fcmodefalse',\"rmfalse\",\"allfalse\",\"anyfalse\",\"notrue\",\"alltrue\",'fcmodetrue',\"rmtrue\",\"anytrue\",\"nofalse\"]\n",
    "crowd_types = [\"origmode\",\"nocnd\",\"modefm\"]\n",
    "\n",
    "types_to_cols= {\"allfalse\":\"all_false_set\",\n",
    "              \"anyfalse\":\"any_false_set\",\n",
    "              \"notrue\":\"no_true\",\n",
    "              \"alltrue\":\"all_true_set\",\n",
    "              \"anytrue\":\"any_true_set\",\n",
    "              \"nofalse\":\"no_false\"}\n",
    "\n",
    "#fc_binary_type = [\"allfalse\",\"anyfalse\",\"notrue\",\"alltrue\",\"anytrue\",\"nofalse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dictionary to save it all in\n",
    "crowd_size_binary = {}\n",
    "\n",
    "for fc_type_it in fc_types:\n",
    "    \n",
    "    for crowd_type_it in crowd_types:\n",
    "        \n",
    "        key = fc_type_it + \"_\" + crowd_type_it\n",
    "        \n",
    "        crowd_size_binary[key] = []\n",
    "\n",
    "\n",
    "min_crowd = 1\n",
    "max_crowd = 11\n",
    "\n",
    "data_df = all_data_fakesource\n",
    "\n",
    "for crowd_size in range(min_crowd,max_crowd):\n",
    "    #print(crowd_size)\n",
    "    #Doing the same for all binary types\n",
    "    for this_type in fc_types:\n",
    "        \n",
    "        #one subset\n",
    "        data_subset = data_df.iloc[:,:crowd_size]\n",
    "        \n",
    "        all_info = full_evaluation(data_subset,data_df,this_type,crowd_types[0])\n",
    "        crowd_size_binary[this_type + \"_\" + crowd_types[0]].append(all_info)\n",
    "        #print(this_type,crowd_types[0],num_correct)\n",
    "       \n",
    "        all_info = full_evaluation(data_subset,data_df,this_type,crowd_types[1])\n",
    "        crowd_size_binary[this_type + \"_\" + crowd_types[1]].append(all_info)\n",
    "        #print(this_type,crowd_types[1],num_correct)\n",
    "\n",
    "        all_info = full_evaluation(data_subset,data_df,this_type,crowd_types[2])\n",
    "        crowd_size_binary[this_type + \"_\" + crowd_types[2]].append(all_info)\n",
    "        #print(this_type,crowd_types[2],num_correct)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crowd_size_binary = pickle.load( open( local_pickles + 'crowd_size_binary.p', \"rb\" ) )\n",
    "pickle.dump(crowd_size_binary, open( heuristic_data + 'crowd_size_binary_high_pol.p', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dictionary to save it all in\n",
    "crowd_size_binary = {}\n",
    "\n",
    "for fc_type_it in fc_types:\n",
    "    \n",
    "    for crowd_type_it in crowd_types:\n",
    "        \n",
    "        key = fc_type_it + \"_\" + crowd_type_it\n",
    "        \n",
    "        crowd_size_binary[key] = []\n",
    "\n",
    "\n",
    "min_crowd = 1\n",
    "max_crowd = 11\n",
    "\n",
    "data_df = test_data_fakesource\n",
    "\n",
    "for crowd_size in range(min_crowd,max_crowd):\n",
    "    #print(crowd_size)\n",
    "    #Doing the same for all binary types\n",
    "    for this_type in fc_types:\n",
    "        \n",
    "        #one subset\n",
    "        data_subset = data_df.iloc[:,:crowd_size]\n",
    "        \n",
    "        all_info = full_evaluation(data_subset,data_df,this_type,crowd_types[0])\n",
    "        crowd_size_binary[this_type + \"_\" + crowd_types[0]].append(all_info)\n",
    "        #print(this_type,crowd_types[0],num_correct)\n",
    "       \n",
    "        all_info = full_evaluation(data_subset,data_df,this_type,crowd_types[1])\n",
    "        crowd_size_binary[this_type + \"_\" + crowd_types[1]].append(all_info)\n",
    "        #print(this_type,crowd_types[1],num_correct)\n",
    "\n",
    "        all_info = full_evaluation(data_subset,data_df,this_type,crowd_types[2])\n",
    "        crowd_size_binary[this_type + \"_\" + crowd_types[2]].append(all_info)\n",
    "        #print(this_type,crowd_types[2],num_correct)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crowd_size_binary = pickle.load( open( local_pickles + 'crowd_size_binary.p', \"rb\" ) )\n",
    "pickle.dump(crowd_size_binary, open( heuristic_data + 'crowd_size_binary_high_pol_test.p', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
