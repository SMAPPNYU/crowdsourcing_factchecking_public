{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author of code: William Godel \n",
    "\n",
    "Date: 07/02\n",
    "\n",
    "Purpose: to take in prepared data, then subset crowds to high political knowledge crowds. It also does this for high CRT crowds, but this data is ultimately not used. \n",
    "\n",
    "Data IN: \n",
    "\n",
    "train_data_large.csv\n",
    "\n",
    "val_data_large.csv\n",
    "\n",
    "train_data_large_covid.csv\n",
    "\n",
    "val_data_large_covid.csv\n",
    "\n",
    "train_data_large_noncovid.csv\n",
    "\n",
    "val_data_large_noncovid.csv\n",
    "\n",
    "test_data_large.csv\n",
    "\n",
    "test_data_large_covid.csv\n",
    "\n",
    "test_data_large_noncovid.csv\n",
    "\n",
    "Data OUT:\n",
    "\n",
    "pol_knowledge_df.p\n",
    "\n",
    "pol_knowledge_df_test.p\n",
    "\n",
    "pol_knowledge_df_val.p\n",
    "\n",
    "pol_knowledge_df_train_orig.p\n",
    "\n",
    "\n",
    "Machine: My laptop or Imac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "laptop = True\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='ML.log',level=logging.DEBUG)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from functions import count_mode, bayes_probs, bayes_binary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from path import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualified crowds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "train_data = pd.read_csv(prepared_data + \"train_data_large.csv\")\n",
    "val_data = pd.read_csv(prepared_data + \"val_data_large.csv\")\n",
    "\n",
    "train_data_covid = pd.read_csv(prepared_data + \"train_data_large_covid.csv\")\n",
    "val_data_covid = pd.read_csv(prepared_data + \"val_data_large_covid.csv\")\n",
    "\n",
    "train_data_noncovid = pd.read_csv(prepared_data + \"train_data_large_noncovid.csv\")\n",
    "val_data_noncovid = pd.read_csv(prepared_data + \"val_data_large_noncovid.csv\")\n",
    "\n",
    "\n",
    "train_data_large = train_data.append(train_data_covid)\n",
    "train_data_large = train_data_large.append(train_data_noncovid)\n",
    "train_data_large.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "val_data_large = val_data.append(val_data_covid)\n",
    "val_data_large = val_data_large.append(val_data_noncovid)\n",
    "val_data_large.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#first time saving target to save for orig\n",
    "train_target_large = train_data_large['mode'] == 'FM'\n",
    "val_target_large = val_data_large['mode'] == 'FM'\n",
    "train_data_large_orig = train_data_large.copy()\n",
    "train_target_large_orig = train_target_large.copy()\n",
    "\n",
    "train_data_large = train_data_large.append(val_data_large)\n",
    "train_target_large = train_target_large.append(val_target_large)\n",
    "#second time saving target for combined train and val\n",
    "train_data_large.reset_index(inplace = True, drop = True)\n",
    "train_target_large = train_data_large['mode'] == 'FM'\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(prepared_data + \"test_data_large.csv\")\n",
    "test_data_covid = pd.read_csv(prepared_data + \"test_data_large_covid.csv\")\n",
    "test_data_noncovid = pd.read_csv(prepared_data + \"test_data_large_noncovid.csv\")\n",
    "\n",
    "test_data_large = test_data.append(test_data_covid)\n",
    "test_data_large = test_data_large.append(test_data_noncovid)\n",
    "\n",
    "test_data_large.reset_index(inplace = True, drop = True)\n",
    "test_target_large = test_data_large['mode'] == 'FM'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Val combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#First, identify rows that are eligibe up to 15.\n",
    "\n",
    "#All respondent columns\n",
    "ideo_cols = [\"ideology_resp_\" +str(x) for x in range(0,60)]\n",
    "resp_cols = [\"resp_cat_\" +str(x) for x in range(0,60)]\n",
    "ver_cols = [\"resp_veracity_\" +str(x) for x in range(0,60)]\n",
    "\n",
    "pol_cols = [\"pol_know_\" +str(x) for x in range(0,60)]\n",
    "crt_cols = [\"crt_\" +str(x) for x in range(0,60)]\n",
    "\n",
    "\n",
    "crowd_size_long = 10\n",
    "\n",
    "def select_crowd_pol(input_array, num_size = 10, threshold = 4):\n",
    "    \n",
    "    keep_list = []\n",
    "    count = 0\n",
    "    \n",
    "    for this_person in input_array:\n",
    "        \n",
    "        if count >= num_size:\n",
    "            \n",
    "            keep_list.append(False)\n",
    "        \n",
    "        elif this_person >= threshold:\n",
    "            \n",
    "            keep_list.append(True)\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            keep_list.append(False)\n",
    "            \n",
    "    if count < num_size:\n",
    "        \n",
    "        #print(\"short\", threshold)\n",
    "        pass\n",
    "    \n",
    "    return keep_list\n",
    "    \n",
    "    \n",
    "mask1 = train_data_large[pol_cols].apply(select_crowd_pol, num_size = crowd_size_long, axis = 1)\n",
    "mask2 = train_data_large[crt_cols].apply(select_crowd_pol, num_size = crowd_size_long, threshold = 2, axis = 1)\n",
    "\n",
    "df_list_pol = []\n",
    "df_list_crt = []\n",
    "\n",
    "for number, series in train_data_large.iterrows():\n",
    "    \n",
    "    df_row_pol = []\n",
    "    df_row_crt = []\n",
    "\n",
    "    mask_list1 = mask1[number]\n",
    "    mask_list2 = mask2[number]\n",
    "    \n",
    "    df_row_pol.extend(list(series[resp_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ver_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ideo_cols][mask_list1]))\n",
    "    #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "    #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "    \n",
    "    df_list_pol.append(df_row_pol)\n",
    "    \n",
    "    if len(list(series[resp_cols][mask_list2])) > 0:\n",
    "    \n",
    "        df_row_crt.extend(list(series[resp_cols][mask_list2]))\n",
    "        df_row_crt.extend(list(series[ver_cols][mask_list2]))\n",
    "        df_row_crt.extend(list(series[ideo_cols][mask_list2]))\n",
    "        #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "        #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "\n",
    "        df_list_crt.append(df_row_crt)\n",
    "    \n",
    "col_list = []\n",
    "col_list.extend(resp_cols[:crowd_size_long])\n",
    "col_list.extend(ver_cols[:crowd_size_long])\n",
    "col_list.extend(ideo_cols[:crowd_size_long])\n",
    "    \n",
    "pol_knowledge_df = pd.DataFrame(df_list_pol, columns = col_list )       \n",
    "pol_knowledge_df['mode'] = train_data_large['mode']\n",
    "\n",
    "crt_df = pd.DataFrame(df_list_crt, columns = col_list )       \n",
    "crt_df['mode'] = train_data_large['mode'].iloc[:crt_df.shape[0]]\n",
    "\n",
    "\n",
    "eval_types = ['in_robust_mode', 'no_false','all_true_set', 'any_true_set', 'no_true', 'all_false_set','any_false_set']\n",
    "\n",
    "for this_type in eval_types:\n",
    "    \n",
    "    pol_knowledge_df[this_type] = train_data_large[this_type]\n",
    "    crt_df[this_type] = train_data_large[this_type].iloc[:crt_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pol_knowledge_df, open(data_pickles + \"pol_knowledge_df.p\", \"wb\"))\n",
    "#pickle.dump(crt_df, open(data_pickles + \"crt_df.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_size_long = 10\n",
    "mask1_test = test_data_large[pol_cols].apply(select_crowd_pol, num_size = crowd_size_long, axis = 1)\n",
    "mask2_test = test_data_large[crt_cols].apply(select_crowd_pol, num_size = crowd_size_long, threshold = 2, axis = 1)\n",
    "\n",
    "df_list_pol_test = []\n",
    "df_list_crt_test = []\n",
    "\n",
    "for number, series in test_data_large.iterrows():\n",
    "    \n",
    "    df_row_pol = []\n",
    "    df_row_crt = []\n",
    "\n",
    "    mask_list1 = mask1_test[number]\n",
    "    mask_list2 = mask2_test[number]\n",
    "    \n",
    "    df_row_pol.extend(list(series[resp_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ver_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ideo_cols][mask_list1]))\n",
    "    #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "    #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "    \n",
    "    df_list_pol_test.append(df_row_pol)\n",
    "    \n",
    "    if len(list(series[resp_cols][mask_list2])) > 0:\n",
    "    \n",
    "        df_row_crt.extend(list(series[resp_cols][mask_list2]))\n",
    "        df_row_crt.extend(list(series[ver_cols][mask_list2]))\n",
    "        df_row_crt.extend(list(series[ideo_cols][mask_list2]))\n",
    "        #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "        #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "\n",
    "        df_list_crt_test.append(df_row_crt)\n",
    "    \n",
    "col_list = []\n",
    "col_list.extend(resp_cols[:crowd_size_long])\n",
    "col_list.extend(ver_cols[:crowd_size_long])\n",
    "col_list.extend(ideo_cols[:crowd_size_long])\n",
    "    \n",
    "pol_knowledge_df_test = pd.DataFrame(df_list_pol_test, columns = col_list )       \n",
    "pol_knowledge_df_test['mode'] = test_data_large['mode']\n",
    "\n",
    "crt_df_test = pd.DataFrame(df_list_crt_test, columns = col_list )       \n",
    "crt_df_test['mode'] = test_data_large['mode'].iloc[:crt_df_test.shape[0]]\n",
    "\n",
    "\n",
    "eval_types = ['in_robust_mode', 'no_false','all_true_set', 'any_true_set', 'no_true', 'all_false_set','any_false_set']\n",
    "\n",
    "for this_type in eval_types:\n",
    "    \n",
    "    pol_knowledge_df_test[this_type] = test_data_large[this_type]\n",
    "    crt_df_test[this_type] = test_data_large[this_type].iloc[:crt_df_test.shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pol_knowledge_df_test, open(data_pickles + \"pol_knowledge_df_test.p\", \"wb\"))\n",
    "#pickle.dump(crt_df_test, open(data_pickles + \"crt_df_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_size_long = 10\n",
    "mask1_test = val_data_large[pol_cols].apply(select_crowd_pol, num_size = crowd_size_long, axis = 1)\n",
    "mask2_test = val_data_large[crt_cols].apply(select_crowd_pol, num_size = crowd_size_long, threshold = 1, axis = 1)\n",
    "\n",
    "df_list_pol_val = []\n",
    "df_list_crt_val = []\n",
    "\n",
    "for number, series in val_data_large.iterrows():\n",
    "    \n",
    "    df_row_pol = []\n",
    "    df_row_crt = []\n",
    "\n",
    "    mask_list1 = mask1_test[number]\n",
    "    mask_list2 = mask2_test[number]\n",
    "    \n",
    "    df_row_pol.extend(list(series[resp_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ver_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ideo_cols][mask_list1]))\n",
    "    #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "    #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "    \n",
    "    df_list_pol_val.append(df_row_pol)\n",
    "    \n",
    "    df_row_crt.extend(list(series[resp_cols][mask_list2]))\n",
    "    df_row_crt.extend(list(series[ver_cols][mask_list2]))\n",
    "    df_row_crt.extend(list(series[ideo_cols][mask_list2]))\n",
    "    #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "    #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "    \n",
    "    df_list_crt_val.append(df_row_crt)\n",
    "    \n",
    "col_list = []\n",
    "col_list.extend(resp_cols[:crowd_size_long])\n",
    "col_list.extend(ver_cols[:crowd_size_long])\n",
    "col_list.extend(ideo_cols[:crowd_size_long])\n",
    "    \n",
    "pol_knowledge_df_val = pd.DataFrame(df_list_pol_val, columns = col_list )       \n",
    "pol_knowledge_df_val['mode'] = val_data_large['mode']\n",
    "\n",
    "crt_df_val = pd.DataFrame(df_list_crt_val, columns = col_list )       \n",
    "crt_df_val['mode'] = val_data_large['mode']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pol_knowledge_df_val, open(data_pickles + \"pol_knowledge_df_val.p\", \"wb\"))\n",
    "#pickle.dump(crt_df_val, open(data_pickles + \"crt_df_val.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "mask1 = train_data_large_orig[pol_cols].apply(select_crowd_pol, num_size = crowd_size_long, axis = 1)\n",
    "mask2 = train_data_large_orig[crt_cols].apply(select_crowd_pol, num_size = crowd_size_long, threshold = 1, axis = 1)\n",
    "\n",
    "df_list_pol = []\n",
    "df_list_crt = []\n",
    "\n",
    "for number, series in train_data_large_orig.iterrows():\n",
    "    \n",
    "    df_row_pol = []\n",
    "    df_row_crt = []\n",
    "\n",
    "    mask_list1 = mask1[number]\n",
    "    mask_list2 = mask2[number]\n",
    "    \n",
    "    df_row_pol.extend(list(series[resp_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ver_cols][mask_list1]))\n",
    "    df_row_pol.extend(list(series[ideo_cols][mask_list1]))\n",
    "    #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "    #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "    \n",
    "    df_list_pol.append(df_row_pol)\n",
    "    \n",
    "    df_row_crt.extend(list(series[resp_cols][mask_list2]))\n",
    "    df_row_crt.extend(list(series[ver_cols][mask_list2]))\n",
    "    df_row_crt.extend(list(series[ideo_cols][mask_list2]))\n",
    "    #df_list.append(list(series[pol_cols][mask_list1]))\n",
    "    #df_list.append(list(series[crt_cols][mask_list1]))\n",
    "    \n",
    "    df_list_crt.append(df_row_crt)\n",
    "    \n",
    "col_list = []\n",
    "col_list.extend(resp_cols[:crowd_size_long])\n",
    "col_list.extend(ver_cols[:crowd_size_long])\n",
    "col_list.extend(ideo_cols[:crowd_size_long])\n",
    "    \n",
    "pol_knowledge_df_orig = pd.DataFrame(df_list_pol, columns = col_list )       \n",
    "pol_knowledge_df_orig['mode'] = train_data_large['mode']\n",
    "\n",
    "crt_df_orig = pd.DataFrame(df_list_crt, columns = col_list )       \n",
    "crt_df_orig['mode'] = train_data_large['mode']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pol_knowledge_df_orig, open(data_pickles + \"pol_knowledge_df_train_orig.p\", \"wb\"))\n",
    "#pickle.dump(crt_df_test, open(data_pickles + \"crt_df_train_orig.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
